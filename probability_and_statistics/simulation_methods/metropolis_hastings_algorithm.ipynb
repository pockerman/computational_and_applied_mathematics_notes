{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce17ef47-213d-425f-b761-e8226e4c0741",
   "metadata": {},
   "source": [
    "# Metropolis-Hastings Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28017709-f559-4f1f-9006-7ad82696d63d",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f399e8-2d9d-4cd3-9762-80b920b0d329",
   "metadata": {},
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm\">Metropolis-Hastings algorithm</a> \n",
    "is another methodology which we can use in order to obtain a sequence of random \n",
    "samples from a probability distribution from which direct sampling is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973500c5-6a05-4522-a34c-b9d213418a63",
   "metadata": {},
   "source": [
    "## Metropolis-Hastings Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e33eb-5a66-46bd-bcc8-ac219b7c29a3",
   "metadata": {},
   "source": [
    "Let's consider once more the integral "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87791b-8c03-4936-bbe9-664520576a75",
   "metadata": {},
   "source": [
    "$$ I = \\int h(x)f(x)dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeffd7e-dd04-4776-836e-975154abdaae",
   "metadata": {},
   "source": [
    "The Metropolis-Hastings algorithm is a \n",
    "<a href=\"https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo\">Markov chain Monte Carlo (MCMC)</a> methodology. The idea in MCMC is to construct a Markov chain say $X_1, X2, \\dots, $whose stationary distribution is $f$ [1]. Under certain conditions, and due to the law of large numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf03f4c-9eec-46ae-9b3e-2e64dcc7332d",
   "metadata": {},
   "source": [
    "$$\\frac{1}{N}\\sum_i h(X_i) \\rightarrow_{P} E\\left[h(X)\\right]=I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed235fec-3af7-4086-9b28-a28ba68ce4ec",
   "metadata": {},
   "source": [
    "Simialr to <a href=\"importance_sampling\">importance sampling</a>, the Metropolis-Hastings algorithm assumes an\n",
    "easy to sample proposal distribution $q(y|x)$. The algorithm then works as follows, see [1],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e2f32e-ff12-4499-93e7-6199a945af0e",
   "metadata": {},
   "source": [
    "1. Start by choosing $X_0$ arbitrarily\n",
    "2. Use the proposal distribution to sample $Y\\sim g(Y|X_i)$\n",
    "3.Evaluate $r$ according to \n",
    "\n",
    "$$r(x,y) = min \\{\\frac{f(y)}{f(x)}\\frac{q(x|y)}{q(y|x)}, 1\\}$$\n",
    "\n",
    "and set\n",
    "\n",
    "$$X_{i+1}=\\begin{case}Y & \\text{with probability} & r \\\\ X_i  \\end{case}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00699311-a726-41cf-882b-94be0e3bda1b",
   "metadata": {},
   "source": [
    "----\n",
    "**Remark**\n",
    "\n",
    "A simple way for the final step is to generate a random value, say $V$ form $U(0,1)$ then set $X_{i+1}=Y$ if $V < r$ and\n",
    "$X_{i+1}=X_i$ otherwise.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda83ce7-4230-4aee-8a42-83778c31bd08",
   "metadata": {},
   "source": [
    "Note that if we choose $q(y|x)$ to be the normal distribution with some variance $\\sigma^2$ centered at $x$ i.e. \n",
    "the current value\n",
    "we are looking at, the $q$ will be  symatric, since the normal distribution is symmetric [1]. In this case, the expression\n",
    "for $r$ above is written as [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68babb5b-90a5-4f50-8381-2f4b7ac1889c",
   "metadata": {},
   "source": [
    "$$r(x,y) = min \\{\\frac{f(y)}{f(x_i)}, 1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f80647-164b-4205-8726-533de6ce8d62",
   "metadata": {},
   "source": [
    "## Computational example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf805f-8051-472e-967d-f9aa5e181d5d",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a43d22-8e78-47f5-9557-4194f8a7cc5f",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bd40e-e95b-4477-bf5c-3550c729ba33",
   "metadata": {},
   "source": [
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
