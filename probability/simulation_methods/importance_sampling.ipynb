{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccab6955-c595-4a7e-bf3e-8bb62bffc36d",
   "metadata": {},
   "source": [
    "# Imprtance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25544010-2991-408e-85a3-59b00ea9e22a",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9861ad67-a1fe-411c-8e5c-04e4f461c53f",
   "metadata": {},
   "source": [
    "Section [Basic Monte Carlo Integration](basic_monte_carlo_integration.ipynb) discussed \n",
    "Monte Carlo integration in its basic form. In this method we need to sample from a known distribution\n",
    "$f$. However, there may be case where it is difficult to sample from $f$. \n",
    "\n",
    "In this section, we will introduce <a href=\"https://en.wikipedia.org/wiki/Importance_sampling\">importance sampling</a>.\n",
    "This is a generalization of the basic Monte Carlo method that overcomes the problem of a difficult distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4b59d-3e0e-4009-a8c8-aed6ba2da223",
   "metadata": {},
   "source": [
    "## Importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b285a52-0cf3-4e81-91b0-81343ad18640",
   "metadata": {},
   "source": [
    "Let us consider once again the integral "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cbaab3-135c-4723-9f21-6ac449f0c32e",
   "metadata": {},
   "source": [
    "$$I=\\int_a^b h(x) dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779c5fc4-cb10-4930-addb-f035ec1836a4",
   "metadata": {},
   "source": [
    "and rewrite it as "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb8e732-3845-4b1e-922b-afda7aaafc4e",
   "metadata": {},
   "source": [
    "$$I=\\int_a^b \\omega(x)f(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0995a8d6-8e03-4c9e-b405-4d57b7606001",
   "metadata": {},
   "source": [
    "In general, there is no guarantee that $f$ will be a known distribution [1]. \n",
    "Importance sampling introduces a new probability distribution $g$, also known as the proposal distribution [2], that we however know how to \n",
    "sample from. Thus we rewrite the integral as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8209fdb5-acb9-4f81-b94a-fd1dd76e750c",
   "metadata": {},
   "source": [
    "$$I=\\int_a^b \\frac{\\omega(x)f(x)}{g(x)}g(x)dx=E_g \\left[Y \\right]$$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ba136a5-5155-4970-8a16-34cb26ba8c0d",
   "metadata": {},
   "source": [
    "where $Y$ is the random variable defined by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29a5f5-1755-462f-8e27-b49b92f822c3",
   "metadata": {},
   "source": [
    "$$Y=\\frac{\\omega(x)f(x)}{g(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e3d31-51de-4590-805e-c2e9e99a1c9e",
   "metadata": {},
   "source": [
    "We can now sample from $g$ and estimate $I$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f94eae-26a6-457d-88da-e335a3d8993b",
   "metadata": {},
   "source": [
    "$$\\hat{I}=\\frac{1}{N}\\sum_i Y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca1811-cc13-4f73-bdeb-a20904bfff03",
   "metadata": {},
   "source": [
    "Just like we did in the Monte Carlo integration section, we can use the law of \n",
    "large numbers and show that $\\hat{I}\\rightarrow I$ in probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618e54f-0e46-4b48-b918-cc0e06f2d212",
   "metadata": {},
   "source": [
    "In importance sampling we draw samples from $g$ and re-weight the integral using importance weights so\n",
    "that the correct distribution is targeted [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94aa15c-ce43-49df-93a8-614e1cd20611",
   "metadata": {},
   "source": [
    "However, $g$ in general has to have a similar shape with $f$. Moreover, it has to  have thicker \n",
    "tails than $f$ otherwise the integral may become infinite [1]. Indeed, consider the second moment\n",
    "of $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea683a58-255a-431b-9501-c320d263d5e8",
   "metadata": {},
   "source": [
    "$$E_g\\left[ Y^2 \\right]=\\int Y^2g(x)dx=\\int \\frac{\\omega^2(x)f^2(x)}{g(x)}dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3373d8c5-564f-439e-af5f-db230ea22313",
   "metadata": {},
   "source": [
    "Thinner tails for $g$ means that it goes fatser to zero than what $f$ does. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686cb5c-281c-4ab0-9a12-ac9078e9ffe6",
   "metadata": {},
   "source": [
    "All in all, a good choice for $g$ is a distribution that is similar to $f$ but with thicker tails. \n",
    "In fact, the optimal choice for $g$ is given by the following theorem [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b6a06-9332-4b99-b0dc-c4cafb0a8a66",
   "metadata": {},
   "source": [
    "## Python example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189ac7e-6954-44bb-97bb-d36b75a551fd",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73da25f-b929-42b2-90e8-07e0adcdbfa7",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3b8f8-bde9-4d71-915a-fd18d5d5eeac",
   "metadata": {},
   "source": [
    "1. Larry Wasserman, _All of Statistics. A Concise Course in Statistical Inference_, Springer 2003.\n",
    "2. <a href=\"https://astrostatistics.psu.edu/su14/lectures/cisewski_is.pdf\">Imporatnce sampling</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf5cfc-4730-4d4d-ab38-80a89d5ada02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
